{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Sense Disambiguation: from start to finish\n",
    "A well-known NLP task is [Word Sense Disambiguation (WSD)](https://en.wikipedia.org/wiki/Word-sense_disambiguation). The goal is to identify the sense of a word in a sentence. Here is an example of the output of one of the best systems, called [Babelfy](http://babelfy.org/index). ![alt text](images/babelfy_output.png \"Babelfy output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since 1998, there have been WSD competitions: [Senseval and SemEval](https://en.wikipedia.org/wiki/SemEval). The idea is very simple. A few people annotate words in a sentence with the correct meaning and systems try to the do same. Because we have the manual annotations, we can score how well each system performs. In this exercise, we are going to compete in [SemEval-2013 task 12: Multilingual Word Sense Disambiguation](https://www.cs.york.ac.uk/semeval-2013/task12.html).\n",
    "\n",
    "The main steps in this exercise are:\n",
    "* Introduction of the data and goals\n",
    "* Performing WSD\n",
    "* Loading manual annotations (which we will call **gold data**)\n",
    "* System output \n",
    "* Write an XML file containing both the gold data and our system output\n",
    "* Read the XML file, evaluate our performance, and perform error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction of the data and goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following data (originating from [SemEval-2013 task 12 test data](https://www.cs.york.ac.uk/semeval-2013/task12/data/uploads/datasets/semeval-2013-task12-test-data.zip)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **system input**: data/multilingual-all-words.en.xml \n",
    "* **gold data**: data/sem2013-aw.key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a word in a sentence, the goal of our system is to determine the corect meaning of that word. For example, look at the **system input** file (data/multilingual-all-words.en.xml) at lines 1724-1740.\n",
    "All the *instance* elements are the ones we have to provide a meaning for. Please note that the *sentence* element has *wf* and *instance* children. The *instance* elements are the ones  for which we have to provide a meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```xml\n",
    "<sentence id=\"d003.s005\">\n",
    "    <wf lemma=\"frankly\" pos=\"RB\">Frankly</wf>\n",
    "    <wf lemma=\",\" pos=\",\">,</wf>\n",
    "    <wf lemma=\"the\" pos=\"DT\">the</wf>\n",
    "    <instance id=\"d003.s005.t001\" lemma=\"market\" pos=\"NN\">market</instance>\n",
    "    <wf lemma=\"be\" pos=\"VBZ\">is</wf>\n",
    "    <wf lemma=\"very\" pos=\"RB\">very</wf>\n",
    "    <wf lemma=\"calm\" pos=\"JJ\">calm</wf>\n",
    "    <wf lemma=\",\" pos=\",\">,</wf>\n",
    "    <wf lemma=\"observe\" pos=\"VVZ\">observes</wf>\n",
    "    <wf lemma=\"Mace\" pos=\"NP\">Mace</wf>\n",
    "    <wf lemma=\"Blicksilver\" pos=\"NP\">Blicksilver</wf>\n",
    "    <wf lemma=\"of\" pos=\"IN\">of</wf>\n",
    "    <wf lemma=\"Marblehead\" pos=\"NP\">Marblehead</wf>\n",
    "    <instance id=\"d003.s005.t002\" lemma=\"asset_management\" pos=\"NE\">Asset_Management</instance>\n",
    "    <wf lemma=\".\" pos=\"SENT\">.</wf>\n",
    "  </sentence>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way to determine the possible meanings of a word, we will use [WordNet](https://wordnet.princeton.edu/). For example, for the lemma **market**, Wordnet lists the following meanings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('market.n.01') the world of commercial activity where goods and services are bought and sold\n",
      "Synset('market.n.02') the customers for a particular product or service\n",
      "Synset('grocery_store.n.01') a marketplace where groceries are sold\n",
      "Synset('market.n.04') the securities markets in the aggregate\n",
      "Synset('marketplace.n.02') an area in a town where a public mercantile establishment is set up\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('market', pos='n'):\n",
    "    print(synset, synset.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to know which meaning the manual annotators chose, we go to the **gold data** (data/sem2013-aw.key). For the identifier *d003.s005.t001*, we find:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d003 d003.s005.t001 market%1:14:01:: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to know to which synset *market%1:14:01::* belongs, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('market.n.04') the securities markets in the aggregate\n"
     ]
    }
   ],
   "source": [
    "lemma = wn.lemma_from_key('market%1:14:01::')\n",
    "synset = lemma.synset()\n",
    "print(synset, synset.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the manual annotators chose **market.n.04**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing WSD\n",
    "As a first step, we will perform WSD. For this, we will use the [**lesk** WSD algorithm](http://www.d.umn.edu/~tpederse/Pubs/banerjee.pdf) as implemented in the [NLTK](http://www.nltk.org/howto/wsd.html). One of the applications of the Lesk algorithm is to determine which senses of words are related. Imagine that **cone** has three senses, and **pine** has three senses (example from [paper](http://www.d.umn.edu/~tpederse/Pubs/banerjee.pdf)):\n",
    "\n",
    "**Cone**\n",
    "* Sense 1: kind of *evergreen tree* with needleâ€“shaped leaves\n",
    "* Sense 2: waste away through sorrow or illness.\n",
    "\n",
    "**Pine**\n",
    "* Sense 1: solid body which narrows to a point\n",
    "* Sense 2: something of this shape whether solid or hollow\n",
    "* Sense 3: fruit of certain *evergreen tree*\n",
    "\n",
    "As you can see, **sense 1 of cone** and **sense 3 of pine** have an overlap in their definitions and hence indicate that these senses are related. This idea can then be used to perform WSD. The words in the sentence of a word are compared against the definition of each sense of word. The word sense that has the highest number of overlapping words between the sentence and the definition of the word sense is chosen as the correct sense according to the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given is a function that allows you to perform WSD on a sentence. The output is a **WordNet sensekey**, hence an identifier of a sense.\n",
    "#### the function is given, but it is important that you understand how to call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank%1:06:01::\n"
     ]
    }
   ],
   "source": [
    "def perform_wsd(sent, lemma, pos):\n",
    "    '''\n",
    "    perform WSD using the lesk algorithm as implemented in the nltk\n",
    "    \n",
    "    :param list sent: list of words\n",
    "    :param str lemma: a lemma\n",
    "    :param str pos: a pos (n | v | a | r)\n",
    "    \n",
    "    :rtype: str\n",
    "    :return: wordnet sensekey or not_found\n",
    "    '''\n",
    "    sensekey = 'not_found'\n",
    "    wsd_result = lesk(sent, lemma, pos)\n",
    "    \n",
    "    if wsd_result is not None:\n",
    "        for lemma_obj in wsd_result.lemmas():\n",
    "            if lemma_obj.name() == lemma:\n",
    "                sensekey = lemma_obj.key()\n",
    "    \n",
    "    return sensekey\n",
    "\n",
    "\n",
    "sent = ['I', 'went', 'to', 'the', 'bank', 'to', 'deposit', 'money', '.']\n",
    "assert perform_wsd(sent, 'bank', 'n')  == 'bank%1:06:01::', 'key is %s' % perform_wsd(sent, 'bank', 'n')\n",
    "assert perform_wsd(sent, 'dfsdf', 'n')  == 'not_found', 'key is %s' % perform_wsd(sent, 'money', 'n')\n",
    "print(perform_wsd(sent, 'bank', 'n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading manual annotations\n",
    "Your job now is to load the manual annotations from 'data/sem2013-aw.key'.\n",
    "Tip, you can use [**repr**](https://docs.python.org/3/library/functions.html#repr) to check which delimiter (space, tab, etc) was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-3-14d7f765ebc5>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-14d7f765ebc5>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    return gold\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def load_gold_data(path_to_gold_key):\n",
    "    '''\n",
    "    given the path to gold data of semeval2013 task 12,\n",
    "    this function creates a dictionary mapping the identifier to the\n",
    "    gold answers\n",
    "    \n",
    "    HINT: sometimes, there is more than one sensekey for identifier\n",
    "    \n",
    "    :param str path_to_gold_key: path to where gold data file is stored\n",
    "    \n",
    "    :rtype: dict\n",
    "    :return: identifier (str) -> goldkeys (set)\n",
    "    '''\n",
    "    gold = {} \n",
    "    with open(path_to_gold_key) as infile:\n",
    "        # complete this part\n",
    "    \n",
    "    return gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check if your functions works correctly by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_gold_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2bf71608b94b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_gold_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/sem2013-aw.key'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1644\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'number of gold items is %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_gold_data' is not defined"
     ]
    }
   ],
   "source": [
    "gold = load_gold_data('data/sem2013-aw.key')\n",
    "assert len(gold) == 1644, 'number of gold items is %s' % len(gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining system input + system output + gold data\n",
    "We are going to create a dictionary that looks like this:\n",
    "```python\n",
    "{10: {'sent_id' : 1\n",
    "      'text': 'banks',\n",
    "      'lemma' : 'bank',\n",
    "      'pos' : 'n',\n",
    "      'instance_id' : 'd003.s005.t001',\n",
    "      'gold_keys' : {'bank%1:14:00::'},\n",
    "      'system_key' : 'bank%1:14:00::'}\n",
    "    }\n",
    "```\n",
    "\n",
    "Combining all relevant information in one dictionary will help us to create the NAF XML file.\n",
    "In order to do this, we will write several functions. To work with XML, we will first import the lxml module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_sentences(semeval_2013_input):\n",
    "    '''\n",
    "    given the path to the semeval input xml,\n",
    "    this function creates a dictionary mapping sentence identfier\n",
    "    to the sentence (list of words)\n",
    "    \n",
    "    HINT: you need the text of all:\n",
    "    text/sentence/instance and text/sentence/wf elements\n",
    "    \n",
    "    :param str semeval_2013_input: path to semeval 2013 input xml\n",
    "    \n",
    "    :rtype: dict\n",
    "    :return: mapping sentence identifier -> list of words\n",
    "    '''\n",
    "    sentences = dict()\n",
    "    \n",
    "    doc = etree.parse(semeval_2013_input)\n",
    "    \n",
    "    # insert code here\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "please check that your function works by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = load_sentences('data/multilingual-all-words.en.xml')\n",
    "assert len(sentences) == 306, 'number of sentences is different from needed 306: namely %s' % len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_input_data(semeval_2013_input):\n",
    "    '''\n",
    "    given the path to input xml file, we will create a dictionary that looks like this:\n",
    "    \n",
    "    :rtype: dict\n",
    "    :return: {10: {\n",
    "                    'sent_id' : 1\n",
    "                    'text': 'banks',\n",
    "                    'lemma' : 'bank',\n",
    "                    'pos' : 'n',\n",
    "                    'instance_id' : 'd003.s005.t001',\n",
    "                    'gold_keys' : {},\n",
    "                    'system_key' : ''}\n",
    "            }\n",
    "    '''\n",
    "    data = dict()\n",
    "    doc = etree.parse(semeval_2013_input)\n",
    "    identifier = 1\n",
    "    \n",
    "    for sent_el in doc.iterfind('text/sentence'):\n",
    "        # insert code here\n",
    "        \n",
    "        for child_el in sent_el.getchildren():\n",
    "            # insert code here\n",
    "            \n",
    "            info = {\n",
    "                'sent_id' : # to fill, \n",
    "                'text': # to fill, \n",
    "                'lemma' : # to fill,\n",
    "                'pos' : # to fill, \n",
    "                'instance_id' : # to fill if instance element else empty string,\n",
    "                'gold_keys' : set(), # this is ok for now\n",
    "                'system_key' : '' # this is ok for now\n",
    "            }\n",
    "            \n",
    "            data[identifier] = info\n",
    "            identifier += 1\n",
    "                    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = load_input_data('data/multilingual-all-words.en.xml')\n",
    "assert len(data) == 8142, 'number of token is not the needed 8142: namely %s' % len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_gold_and_wsd_output(data, gold, sentences): \n",
    "    '''\n",
    "    the goal of this function is to fill the keys 'system_key'\n",
    "    and 'gold_keys' for the entries in which the 'instance_id' is not an empty string.\n",
    "    \n",
    "    :param dict data: see output function 'load_input_data'\n",
    "    :param dict gold: see output function 'load_gold_data' \n",
    "    :param dict sentences: see output function 'load_sentences' \n",
    "    \n",
    "    NOTE: not all instance_ids have a gold answer! \n",
    "    \n",
    "    :rtype: dict\n",
    "    :return: {10: {'sent_id' : 1\n",
    "      'text': 'banks',\n",
    "      'lemma' : 'bank',\n",
    "      'pos' : 'n',\n",
    "      'instance_id' : 'd003.s005.t001',\n",
    "      'gold_keys' : {'bank%1:14:00::'},\n",
    "      'system_key' : 'bank%1:14:00::'}\n",
    "    }\n",
    "    '''\n",
    "    for identifier, info in data.items():\n",
    "        # get the instance id\n",
    "        \n",
    "        if instance_id:\n",
    "            # perform wsd and get sensekey that lesk proposes\n",
    "            \n",
    "            # add system key to our dictionary\n",
    "            # info['system_key'] = sensekey\n",
    "            \n",
    "            if instance_id in gold:\n",
    "                info['gold_keys'] = gold[instance_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function to combine all information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_gold_and_wsd_output(data, gold, sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NAF with system run and gold information\n",
    "We are going to create one [NAF XML](http://www.newsreader-project.eu/files/2013/01/techreport.pdf) containing both the gold information and our system run. In order to do this, we will guide you through the process of doing this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step a: create an xml object\n",
    "**NAF** will be our root element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_root = etree.Element('NAF')\n",
    "new_tree = etree.ElementTree(new_root)\n",
    "new_root = new_tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect what we have created by using the **etree.dump** method. As you can see, we only have the root node **NAF** currently in our document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NAF/>\n"
     ]
    }
   ],
   "source": [
    "etree.dump(new_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step b: add children\n",
    "We will now add the elements in which we will place the **wf** and **term** elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_el = etree.Element('text')\n",
    "terms_el = etree.Element('terms')\n",
    "\n",
    "new_root.append(text_el)\n",
    "new_root.append(terms_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NAF>\n",
      "  <text/>\n",
      "  <terms/>\n",
      "</NAF>\n"
     ]
    }
   ],
   "source": [
    "etree.dump(new_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step c: functions to create wf and term elements\n",
    "#### TIP: check the subsection *Creating your own XML elements* from Topic 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_wf_element(identifier, sent_id, text):\n",
    "    '''\n",
    "    create NAF wf element, such as:\n",
    "    <wf id=\"11\" sent_id=\"d001.s002\">conference</wf>\n",
    "    \n",
    "    :param int identifier: our own identifier (convert this to string)\n",
    "    :param str sent_id: the sentence id of the competition\n",
    "    :param str text: the text\n",
    "    '''\n",
    "    # complete from here\n",
    "    wf_el = etree.Element(\n",
    "    \n",
    "    return wf_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_term_element(identifier, instance_id, system_key, gold_keys):\n",
    "    '''\n",
    "    create NAF xml element, such as:\n",
    "    <term id=\"3885\">\n",
    "      <externalRef instance_id=\"d007.s013.t004\" provenance=\"lesk\" wordnetkey=\"player%1:18:04::\"/>\n",
    "      <externalRef instance_id=\"d007.s013.t004\" provenance=\"gold\" wordnetkey=\"player%1:18:01::\"/>\n",
    "    </term>\n",
    "    \n",
    "    :param int identifier: our own identifier (convert this to string)\n",
    "    :param str system_key: system output\n",
    "    :param set gold_keys: goldkeys\n",
    "    '''\n",
    "    # complete code here\n",
    "    term_el = etree.Element(\n",
    "    \n",
    "    return term_el"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step d: add wf and term elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for identifier, info in data.items():\n",
    "    wf_el = create_wf_element(identifier, info['sent_id'], info['text'])\n",
    "    text_el.append(wf_el)\n",
    "    \n",
    "    term_el = create_term_element(identifier, \n",
    "                                  info['instance_id'],\n",
    "                                  info['system_key'], \n",
    "                                  info['gold_keys'])\n",
    "    terms_el.append(term_el)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('semeval2013_run1.naf', 'wb') as outfile:\n",
    "    new_tree.write(outfile,\n",
    "                   pretty_print=True,\n",
    "                   xml_declaration=True,\n",
    "                   encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score our system run\n",
    "Read the NAF file and extract relevant statistics, such as:\n",
    "* overall performance (how many are correct?)\n",
    "* [optional]: anything that you find interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
