{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 2 - Diving into unstructured and structured data\n",
    "\n",
    "This week, we will talk about working with unstructured and structured data in Python. So what is the difference between them? Structured data is information with a high degree of organization, which can easily be ordered and processed by machines. You can compare it with a perfectly organized filing cabinet where everything is identified, labeled and easy to access. Unstructured data, however, is not organized in a pre-defined manner and therefore lacks structure. \n",
    "\n",
    "- plain text\n",
    "- CSV and TSV\n",
    "- JSON\n",
    "- XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with files: plain text\n",
    "\n",
    "When doing text analysis, you will often work files that contain plain text. These files typically end with the `.txt` extension. In Python, you can read the content of a file, store it as the type of object that you need (string, list, etc.) and manipulate it (e.g. replacing or removing words). You can also write new content to an existing or a new file.\n",
    "\n",
    "### Reading files\n",
    "Let's start with opening a file in Python. To do this, we need to associate the file on disk with a variable in Python. First, we tell Python where the file is stored on your disk. The location of your file is often referred to as the file path. Python will start looking in the 'working' or 'current' directory (which often will be where your Python script is). If it's in the working directory, you only have to tell Python the name of the file (e.g. `colors.txt`). If it's not in the working directory, you have to tell Python the exact path to your file. We will create a string variable to store this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = \"./texts/charlie.txt\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the single dot in the beginning of the file path; this means 'the current directory'. When writing a file path, you can use the following:\n",
    "- /     means the root of the current drive; \n",
    "- ./    means the current directory;\n",
    "- ../   means the parent of the current directory.  \t \n",
    "\n",
    "\n",
    "Now Python knows where your file is stored, we can open the file by using the built-in function `open()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "infile = open(filename, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `open()` function requires requires the file path as its first argument. The second argument specifies the *mode* in which the file is opened. The mode you choose will depend on what you wish to do with the file. Here are some of our mode options:\n",
    "\n",
    "- 'r' : use for reading\n",
    "- 'w' : use for writing\n",
    "- 'x' : use for creating and writing to a new file\n",
    "- 'a' : use for appending to a file\n",
    "- 'r+' : use for reading and writing to the same file\n",
    "\n",
    "Let's now print `infile`. What do you think will happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='./texts/charlie.txt' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "print(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Hey! That's not what I expected to happen!\", you might think. Python is not printing the contents of the file but only some mysterious mention of some `TextIOWrapper`. This `TextIOWrapper` thing is Python's way of saying it has *opened* a connection to the file `charlie.txt`. In order to *read* the contents of the file we must add the function `read()` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charlie Bucket stared around the gigantic room in which he now found himself. The place was like a witch’s kitchen! All about him black metal pots were boiling and bubbling on huge stoves, and kettles were hissing and pans were sizzling, and strange iron machines were clanking and spluttering, and there were pipes running all over the ceiling and walls, and the whole place was filled with smoke and steam and delicious rich smells. \n",
      "\n",
      "Mr Wonka himself had suddenly become even more excited than usual, and anyone could see that this was the room he loved best of all. He was hopping about among the saucepans and the machines like a child among his Christmas presents, not knowing which thing to look at first. He lifted the lid from a huge pot and took a sniff; then he rushed over and dipped a finger into a barrel of sticky yellow stuff and had a taste; then he skipped across to one of the machines and turned half a dozen knobs this way and that; then he peered anxiously through the glass door of a gigantic oven, rubbing his hands and cackling with delight at what he saw inside. Then he ran over to another machine, a small shiny affair that kept going phut-phut-phut-phut-phut, and every time it went phut, a large green marble dropped out of it into a basket on the floor.\n"
     ]
    }
   ],
   "source": [
    "content = infile.read()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The variable `content` now holds the contents of the file `charlie.txt` and we can access and manipulate it just like any other string. After we read the contents of a file, the `TextWrapper` no longer needs to be open. In fact, it is good practice to close it as soon as you do not need it anymore. Now, lo and behold, we can achieve that with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week, we have done several exercises with manipulating strings. Let's recap. We have learned that some of the most common preprocessing steps are casefolding/lowercasing, punctuation removal and stemming/lemmatization. Did you know that there are some very useful NLP toolkits and modules to do some of these steps? One of these toolkits is the NLTK toolkit. You can simply import this toolkit by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amongst other things, the NLTK toolkit allows you to tokenize texts with the function `nltk.word_tokenize()`. To be able to use this function, we first need to download the NLTK Tokenizer Models. Run the following command to open an installation window. Go to the `Models` tab and select `punkt` from under the `Identifier` column. Also select `averaged_perceptron_tagger`; we will use that later. Then click `Download` and it will install the necessary files. Close the installation window once you are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try tokenizing our Charlie story!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Charlie', 'Bucket', 'stared', 'around', 'the', 'gigantic', 'room', 'in', 'which', 'he', 'now', 'found', 'himself', '.', 'The', 'place', 'was', 'like', 'a', 'witch’s', 'kitchen', '!', 'All', 'about', 'him', 'black', 'metal', 'pots', 'were', 'boiling', 'and', 'bubbling', 'on', 'huge', 'stoves', ',', 'and', 'kettles', 'were', 'hissing', 'and', 'pans', 'were', 'sizzling', ',', 'and', 'strange', 'iron', 'machines', 'were', 'clanking', 'and', 'spluttering', ',', 'and', 'there', 'were', 'pipes', 'running', 'all', 'over', 'the', 'ceiling', 'and', 'walls', ',', 'and', 'the', 'whole', 'place', 'was', 'filled', 'with', 'smoke', 'and', 'steam', 'and', 'delicious', 'rich', 'smells', '.', 'Mr', 'Wonka', 'himself', 'had', 'suddenly', 'become', 'even', 'more', 'excited', 'than', 'usual', ',', 'and', 'anyone', 'could', 'see', 'that', 'this', 'was', 'the', 'room', 'he', 'loved', 'best', 'of', 'all', '.', 'He', 'was', 'hopping', 'about', 'among', 'the', 'saucepans', 'and', 'the', 'machines', 'like', 'a', 'child', 'among', 'his', 'Christmas', 'presents', ',', 'not', 'knowing', 'which', 'thing', 'to', 'look', 'at', 'first', '.', 'He', 'lifted', 'the', 'lid', 'from', 'a', 'huge', 'pot', 'and', 'took', 'a', 'sniff', ';', 'then', 'he', 'rushed', 'over', 'and', 'dipped', 'a', 'finger', 'into', 'a', 'barrel', 'of', 'sticky', 'yellow', 'stuff', 'and', 'had', 'a', 'taste', ';', 'then', 'he', 'skipped', 'across', 'to', 'one', 'of', 'the', 'machines', 'and', 'turned', 'half', 'a', 'dozen', 'knobs', 'this', 'way', 'and', 'that', ';', 'then', 'he', 'peered', 'anxiously', 'through', 'the', 'glass', 'door', 'of', 'a', 'gigantic', 'oven', ',', 'rubbing', 'his', 'hands', 'and', 'cackling', 'with', 'delight', 'at', 'what', 'he', 'saw', 'inside', '.', 'Then', 'he', 'ran', 'over', 'to', 'another', 'machine', ',', 'a', 'small', 'shiny', 'affair', 'that', 'kept', 'going', 'phut-phut-phut-phut-phut', ',', 'and', 'every', 'time', 'it', 'went', 'phut', ',', 'a', 'large', 'green', 'marble', 'dropped', 'out', 'of', 'it', 'into', 'a', 'basket', 'on', 'the', 'floor', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(content)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we now have a list of all words in the text. The punctuation marks are also in the list, but as separate tokens. Another thing that NLTK can do for you is to split a text into sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Charlie Bucket stared around the gigantic room in which he now found himself.', 'The place was like a witch’s kitchen!', 'All about him black metal pots were boiling and bubbling on huge stoves, and kettles were hissing and pans were sizzling, and strange iron machines were clanking and spluttering, and there were pipes running all over the ceiling and walls, and the whole place was filled with smoke and steam and delicious rich smells.', 'Mr Wonka himself had suddenly become even more excited than usual, and anyone could see that this was the room he loved best of all.', 'He was hopping about among the saucepans and the machines like a child among his Christmas presents, not knowing which thing to look at first.', 'He lifted the lid from a huge pot and took a sniff; then he rushed over and dipped a finger into a barrel of sticky yellow stuff and had a taste; then he skipped across to one of the machines and turned half a dozen knobs this way and that; then he peered anxiously through the glass door of a gigantic oven, rubbing his hands and cackling with delight at what he saw inside.', 'Then he ran over to another machine, a small shiny affair that kept going phut-phut-phut-phut-phut, and every time it went phut, a large green marble dropped out of it into a basket on the floor.']\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(content)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now do all sorts of cool things with these lists. For example, we can search for all words that have certain letters in them and add them to a list. Let's say we want to find all present participles in the text. We know that present participles end with *-ing*, so we can do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boiling', 'bubbling', 'hissing', 'sizzling', 'clanking', 'spluttering', 'running', 'ceiling', 'hopping', 'knowing', 'thing', 'rubbing', 'cackling', 'going']\n"
     ]
    }
   ],
   "source": [
    "present_participles = []\n",
    "for token in tokens:\n",
    "    if token.endswith(\"ing\"):\n",
    "        present_participles.append(token)\n",
    "print(present_participles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good! We now have a list of words like *boiling*, *sizzling*, etc. But wait... Oops, there is one word in the list that actually is not a present participle! Of course, also other words can end with *-ing*. So if we want to find all present participles, we have to come up with a smarter solution. Once again, NLTK comes to the rescue with its Part of Speech (POS) tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Charlie', 'NNP'), ('Bucket', 'NNP'), ('stared', 'VBD'), ('around', 'IN'), ('the', 'DT'), ('gigantic', 'JJ'), ('room', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('he', 'PRP'), ('now', 'RB'), ('found', 'VBD'), ('himself', 'PRP'), ('.', '.'), ('The', 'DT'), ('place', 'NN'), ('was', 'VBD'), ('like', 'IN'), ('a', 'DT'), ('witch’s', 'JJ'), ('kitchen', 'NN'), ('!', '.'), ('All', 'DT'), ('about', 'IN'), ('him', 'PRP'), ('black', 'JJ'), ('metal', 'NN'), ('pots', 'NNS'), ('were', 'VBD'), ('boiling', 'VBG'), ('and', 'CC'), ('bubbling', 'VBG'), ('on', 'IN'), ('huge', 'JJ'), ('stoves', 'NNS'), (',', ','), ('and', 'CC'), ('kettles', 'NNS'), ('were', 'VBD'), ('hissing', 'VBG'), ('and', 'CC'), ('pans', 'NNS'), ('were', 'VBD'), ('sizzling', 'VBG'), (',', ','), ('and', 'CC'), ('strange', 'JJ'), ('iron', 'NN'), ('machines', 'NNS'), ('were', 'VBD'), ('clanking', 'VBG'), ('and', 'CC'), ('spluttering', 'NN'), (',', ','), ('and', 'CC'), ('there', 'EX'), ('were', 'VBD'), ('pipes', 'NNS'), ('running', 'VBG'), ('all', 'DT'), ('over', 'IN'), ('the', 'DT'), ('ceiling', 'NN'), ('and', 'CC'), ('walls', 'NNS'), (',', ','), ('and', 'CC'), ('the', 'DT'), ('whole', 'JJ'), ('place', 'NN'), ('was', 'VBD'), ('filled', 'VBN'), ('with', 'IN'), ('smoke', 'NN'), ('and', 'CC'), ('steam', 'NN'), ('and', 'CC'), ('delicious', 'JJ'), ('rich', 'JJ'), ('smells', 'NNS'), ('.', '.'), ('Mr', 'NNP'), ('Wonka', 'NNP'), ('himself', 'PRP'), ('had', 'VBD'), ('suddenly', 'RB'), ('become', 'VBN'), ('even', 'RB'), ('more', 'RBR'), ('excited', 'JJ'), ('than', 'IN'), ('usual', 'JJ'), (',', ','), ('and', 'CC'), ('anyone', 'NN'), ('could', 'MD'), ('see', 'VB'), ('that', 'IN'), ('this', 'DT'), ('was', 'VBD'), ('the', 'DT'), ('room', 'NN'), ('he', 'PRP'), ('loved', 'VBD'), ('best', 'JJS'), ('of', 'IN'), ('all', 'DT'), ('.', '.'), ('He', 'PRP'), ('was', 'VBD'), ('hopping', 'VBG'), ('about', 'IN'), ('among', 'IN'), ('the', 'DT'), ('saucepans', 'NNS'), ('and', 'CC'), ('the', 'DT'), ('machines', 'NNS'), ('like', 'IN'), ('a', 'DT'), ('child', 'NN'), ('among', 'IN'), ('his', 'PRP$'), ('Christmas', 'NNP'), ('presents', 'NNS'), (',', ','), ('not', 'RB'), ('knowing', 'VBG'), ('which', 'WDT'), ('thing', 'NN'), ('to', 'TO'), ('look', 'VB'), ('at', 'IN'), ('first', 'RB'), ('.', '.'), ('He', 'PRP'), ('lifted', 'VBD'), ('the', 'DT'), ('lid', 'NN'), ('from', 'IN'), ('a', 'DT'), ('huge', 'JJ'), ('pot', 'NN'), ('and', 'CC'), ('took', 'VBD'), ('a', 'DT'), ('sniff', 'NN'), (';', ':'), ('then', 'RB'), ('he', 'PRP'), ('rushed', 'VBD'), ('over', 'RB'), ('and', 'CC'), ('dipped', 'VBD'), ('a', 'DT'), ('finger', 'NN'), ('into', 'IN'), ('a', 'DT'), ('barrel', 'NN'), ('of', 'IN'), ('sticky', 'JJ'), ('yellow', 'JJ'), ('stuff', 'NN'), ('and', 'CC'), ('had', 'VBD'), ('a', 'DT'), ('taste', 'NN'), (';', ':'), ('then', 'RB'), ('he', 'PRP'), ('skipped', 'VBD'), ('across', 'IN'), ('to', 'TO'), ('one', 'CD'), ('of', 'IN'), ('the', 'DT'), ('machines', 'NNS'), ('and', 'CC'), ('turned', 'VBD'), ('half', 'PDT'), ('a', 'DT'), ('dozen', 'NN'), ('knobs', 'NN'), ('this', 'DT'), ('way', 'NN'), ('and', 'CC'), ('that', 'IN'), (';', ':'), ('then', 'RB'), ('he', 'PRP'), ('peered', 'VBD'), ('anxiously', 'RB'), ('through', 'IN'), ('the', 'DT'), ('glass', 'NN'), ('door', 'NN'), ('of', 'IN'), ('a', 'DT'), ('gigantic', 'JJ'), ('oven', 'NN'), (',', ','), ('rubbing', 'VBG'), ('his', 'PRP$'), ('hands', 'NNS'), ('and', 'CC'), ('cackling', 'VBG'), ('with', 'IN'), ('delight', 'NN'), ('at', 'IN'), ('what', 'WP'), ('he', 'PRP'), ('saw', 'VBD'), ('inside', 'RB'), ('.', '.'), ('Then', 'RB'), ('he', 'PRP'), ('ran', 'VBD'), ('over', 'RB'), ('to', 'TO'), ('another', 'DT'), ('machine', 'NN'), (',', ','), ('a', 'DT'), ('small', 'JJ'), ('shiny', 'NN'), ('affair', 'NN'), ('that', 'WDT'), ('kept', 'VBD'), ('going', 'VBG'), ('phut-phut-phut-phut-phut', 'NN'), (',', ','), ('and', 'CC'), ('every', 'DT'), ('time', 'NN'), ('it', 'PRP'), ('went', 'VBD'), ('phut', 'NN'), (',', ','), ('a', 'DT'), ('large', 'JJ'), ('green', 'JJ'), ('marble', 'NN'), ('dropped', 'VBD'), ('out', 'IN'), ('of', 'IN'), ('it', 'PRP'), ('into', 'IN'), ('a', 'DT'), ('basket', 'NN'), ('on', 'IN'), ('the', 'DT'), ('floor', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_tagged = nltk.pos_tag(tokens)\n",
    "print(pos_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list of tuples. The first element of the tuple is the token, the second element indicates the part of speech of the token. In this tagset, the `VBG` tag is used for present participles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boiling', 'bubbling', 'hissing', 'sizzling', 'clanking', 'running', 'hopping', 'knowing', 'rubbing', 'cackling', 'going']\n"
     ]
    }
   ],
   "source": [
    "# Finish the following code:\n",
    "present_participles = []\n",
    "for token in pos_tagged:\n",
    "    # if the PoS (second element) is \"VGB\"...\n",
    "        # append the word (first element) to the list\n",
    "print(present_participles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following list: ['boiling', 'bubbling', 'hissing', 'sizzling', 'clanking', 'running', 'hopping', 'knowing', 'rubbing', 'cackling', 'going']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV and TSV (tables)\n",
    "Now let's move on to structured data. There are several data forms, the most common of which is probably the table. A table represents a set of data points as a series of rows, with a column for each of the data points' properties. Tabular data can be encoded as CSV (comma-separated values) or TSV (tab-separated values).\n",
    "\n",
    "CSV and TSV files are simply plain text files in which each line represents a row and, within each line, a comma (for CSV) or a tab character (for TSV) separates the cells in the row (the columns). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON\n",
    "More information will follow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML\n",
    "More information will folow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
