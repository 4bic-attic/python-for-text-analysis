{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting and processing data\n",
    "\n",
    "This week, we will cover the topic of getting and processing data. Given a research problem, where can you find the relevant data? How do you obtain the data? And how do you actually process the data? This notebook aims to guide you through the process.\n",
    "\n",
    "**At the end of this week, you will be able to:**\n",
    "- Get data from the web using an API or the `requests` library.\n",
    "- Process data from the web using different tools.\n",
    "- Use generator functions.\n",
    "\n",
    "**This requires that you already have (some) knowledge about:**\n",
    "- JSON files\n",
    "- files, loops and functions\n",
    "\n",
    "**If you want to learn more about these topics, you might find the following links useful:**\n",
    "- Video: [Loop like a native](http://nedbatchelder.com/text/iter.html)\n",
    "\n",
    "**Important**: Please install the following modules before class:\n",
    "- GeoPy -- use `pip install geopy`\n",
    "- pyspotlight -- use `pip install pyspotlight`\n",
    "- SpaCy\n",
    "\n",
    "To install SpaCy, enter the following commands on the command line.\n",
    "\n",
    "* `conda config --add channels spacy` on the command line\n",
    "* `conda install spacy`. \n",
    "* `python -m spacy.en.download` (if this doesn't work, see [here](http://spacy.io/docs/#getting-started) for updated instructions).\n",
    "\n",
    "## Where to find data\n",
    "\n",
    "**Curated**\n",
    "\n",
    "* Corpora (Brown ([NLTK version](http://www.nltk.org/book/ch02.html)), [OANC](http://www.anc.org/data/oanc/download/), [UMBC WebBase](http://ebiquity.umbc.edu/resource/html/id/351))\n",
    "* Psycholinguistic data (sometimes known as 'norms' in the Psychology literature)\n",
    "* DBpedia\n",
    "* Open data (e.g. [Dutch](https://data.overheid.nl/), [American](https://www.data.gov/))\n",
    "* Web N-gram data (e.g. [here](http://hpsg.fu-berlin.de/cow/ngrams/))\n",
    "\n",
    "**The web**\n",
    "\n",
    "* [USENET](http://www.psych.ualberta.ca/~westburylab/downloads/usenetcorpus.download.html)\n",
    "* [Internet Archive](https://archive.org/)\n",
    "* [Project Gutenberg](https://www.gutenberg.org/)\n",
    "* Wikipedia ([dumps](https://dumps.wikimedia.org/), [export]())\n",
    "* [Web data commons](http://webdatacommons.org/)\n",
    "\n",
    "**Do it yourself**\n",
    "\n",
    "* [BootCat](http://bootcat.sslmit.unibo.it/)\n",
    "* Experiments\n",
    "* Annotating\n",
    "* Crowdsourcing\n",
    "* ...\n",
    "\n",
    "## How to get the data\n",
    "\n",
    "### Downloading directly\n",
    "\n",
    "Here are three ways to download data from the web, each with their own use cases.\n",
    "\n",
    "* Browser (loads of data available online)\n",
    "* Command line: `wget` ([manual](https://www.gnu.org/software/wget/manual/wget.html))\n",
    "* Python: `requests`, `urllib`\n",
    "\n",
    "If you see some dataset online, or you just want to download a webpage, there is no better way than to use your browser and either save the page (from the File menu), or to right-click and press \"save as..\". But for more complex cases, you'll want to automate the process. \n",
    "\n",
    "The command line `wget` tool is like a swiss pocket knife for downloading stuff in bulk. For example, if you have a list of URLs in a text file called `list_of_urls.txt`, you can just use `wget -i list_of_urls.txt` to download all the files. You can also use the `wget` module in Python. For more complicated procedures, it's easier to just use the `requests` or `urllib` library.\n",
    "\n",
    "Here is how we downloaded the Linguist List data for this course:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import urllib.request\n",
    "import time\n",
    "\n",
    "base_url = 'http://listserv.linguistlist.org/pipermail/linglite/'\n",
    "years = [str(year) for year in range(1997,2016)]\n",
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
    "          'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "for year in years:\n",
    "    # OS-independent way of creating the path to the folder.\n",
    "    path = os.path.join('..', 'linguistlist', year)\n",
    "    # Make the necessary folder.\n",
    "    os.makedirs(path)\n",
    "    \n",
    "    for month in months:\n",
    "        # Update variables.\n",
    "        filename = '{}-{}.txt.gz'.format(year, month)\n",
    "        path_with_file = os.path.join(path, filename)\n",
    "        url = base_url + filename\n",
    "        \n",
    "        # Write the data to disk.\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            # Use the 'wb' flag because the response contents are bytes.\n",
    "            with open(path_with_file, 'wb') as outfile:\n",
    "                data = response.read()\n",
    "                outfile.write(data)\n",
    "        \n",
    "        # Be nice to the server.\n",
    "        time.sleep(2)\n",
    "```\n",
    "\n",
    "How did we do this?\n",
    "\n",
    "* First, we went to the [Linguist List archive website](http://listserv.linguistlist.org/pipermail/linglite/). The archive looks nice, but it's a lot of work to download all of those files by hand!\n",
    "* Then, we inspected the **source** of the webpage. In Firefox, you can do this by going to `Tools/Developer/Page Source`. In Chrome: `View/Developer/View Source`. Most other browsers offer this functionality as well.\n",
    "* We saw that the URLs for the monthly archives are very regular. This is good, it means that we can exploit this regularity.\n",
    "* Then, we decided on a local structure: we want to have one folder for every year, in which all the archives for that year are stored. This structure determined the structure of our program.\n",
    "* If you don't download files often, search online for a good way to do this. Many programmers would be lost without Google/StackOverflow! The first thing we found was the `urllib` library. But a solution using the `requests` library would also be OK! That would look like this:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "# Get the data:\n",
    "r = requests.get('http://listserv.linguistlist.org/pipermail/linglite/2016-September.txt.gz')\n",
    "\n",
    "# Use the 'wb' flag because the response contents are bytes.\n",
    "with open('September.txt.gz','wb') as f:\n",
    "\t# Write the data:\n",
    "\tf.write(r.content)\n",
    "```\n",
    "\n",
    "* It turns out that you can use a context manager (`with`-statement) to treat online sources as files. Cool! That means we can use two context managers (1) to get the file from the internet, and (2) to write the file to disk.\n",
    "* It's good practice to make your computer wait a little between requests. So we used the `sleep` function from the `time` module to wait 2 seconds after each download.\n",
    "\n",
    "\n",
    "#### Class discussion\n",
    "This was a simple example that doesn't require us to do any parsing of the webpage itself. But how would you write a function that takes a URL like [this one](http://listserv.linguistlist.org/pipermail/linguist/2016-September/date.html) and returns all job descriptions? What would be your approach (on a high level)? \n",
    "\n",
    "We will revisit this problem below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an API\n",
    "\n",
    "An API (*application programming interface*) provides a way for programs to interact with applications running independently. Those applications could either be running on your own computer, or they could be running somewhere else. We will be working with online APIs, specifically APIs providing the interface to some database. \n",
    "\n",
    "General guidelines for using APIs:\n",
    "\n",
    "1. Try to minimize the number of requests you make. Can you be selective before putting in your requests? \n",
    "2. Try to spread your requests so that you don't overload the server.\n",
    "3. Try to cache your results so that you don't request the same thing twice. (Think about multiple sessions and testing your code.)\n",
    "\n",
    "In short: developers providing APIs are doing us a favor. Acting nice to them is the least we can do.\n",
    "\n",
    "#### Bare APIs and wrappers\n",
    "\n",
    "APIs work like this: you send them a request (possibly with some additional information), and they send you the relevant data back. Sometimes you have to send these requests explicitly in your code, but other times there will be a *wrapper* where people have written code to provide a nice interface for you to use.\n",
    "\n",
    "**Geopy** is a nice example of a wrapper around several geolocation APIs. Read the documentation [here](https://geopy.readthedocs.io/en/1.10.0/). You can install Geopy using `pip install geopy`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the Nominatim API.\n",
    "# Read more about Nominatim here: http://wiki.openstreetmap.org/wiki/Nominatim\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Instantiate a geolocator object, using the Nominatim API.\n",
    "geolocator = Nominatim()\n",
    "\n",
    "# Try to find out more about a place, such as the street where the VU main building is.\n",
    "location = geolocator.geocode('de Boelelaan')\n",
    "\n",
    "# Print the place.\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What kind of information can you get from the `Location` object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some code to get you started if you ever want to use this API. Interesting aspects are:\n",
    "\n",
    "* Caching: this code stores the latitude and longitude for each place in a dictionary called `location_cache`.\n",
    "* Try & Except: this code makes use of two try-except blocks. Typically, code following `try` is the default case, and the code following `except` is for handling situations where the code in the try-block cannot be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('location_cache.json') as f:\n",
    "        location_cache = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    location_cache = dict()\n",
    "\n",
    "def get_lon_lat(place, location_cache):\n",
    "    \"\"\"\n",
    "    Get the latitude and longitude of a place.\n",
    "    \"\"\"\n",
    "    # Start the try-except block. We assume that the data is stored in the location cache,\n",
    "    # but revert to the API otherwise.\n",
    "    try:\n",
    "        # Get the longitude and latitude from the location cache.\n",
    "        lon, lat = location_cache[place]\n",
    "    \n",
    "    # If 'place' is not in the location cache..\n",
    "    except KeyError:\n",
    "        location = geolocator.geocode(place)\n",
    "        lon,lat  = location.longitude, location.latitude\n",
    "        location_cache[place] = [lon, lat]\n",
    "    # return longitude and latitude.\n",
    "    return lon, lat\n",
    "\n",
    "# REST OF YOUR CODE. Example:\n",
    "lon,lat = get_lon_lat('Amsterdam')\n",
    "\n",
    "# Write out the file.\n",
    "with open('location_cache.json', 'w') as f:\n",
    "    son.dump(location_cache, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is friendly to the server, because it only makes a request if you haven't already asked where Amsterdam is. Otherwise it just returns the values from the cache. But we can make it even more friendly by making the computer wait a little between each request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for location in ['Amsterdam', 'Utrecht', 'Amersfoort', 'Uitgeest']:\n",
    "    # Make the request.\n",
    "    lon, lat = get_lon_lat(location, location_cache)\n",
    "    \n",
    "    # Do something with the result, e.g. print it.\n",
    "    print(location, 'has the following longitude and latitude:', lon, ';', lat)\n",
    "\n",
    "    # Wait.\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is no wrapper, you just treat the API as if you are downloading something from the URL. Let's go through some examples. Both of these provide output in JSON format.\n",
    "\n",
    "**Recipepuppy** is a website where you can search for recipes you can make with a particular set of ingredients. The description of their API is [here](http://www.recipepuppy.com/about/api/). So how do we make this work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This library comes pre-installed with Anaconda. We use it to send requests to the web.\n",
    "import requests\n",
    "\n",
    "# Get the ingredients\n",
    "ingredients = input('Please enter the ingredients as a comma-separated list.\\n')\n",
    "\n",
    "# Remove spaces if there are any. (This makes the script more robust.)\n",
    "ingredients.replace(' ','')\n",
    "\n",
    "# Prepare the API request URL\n",
    "base_url = \"http://www.recipepuppy.com/api/?i=\"\n",
    "api_request = base_url + ingredients\n",
    "\n",
    "# Get the response\n",
    "response = requests.get(api_request)\n",
    "\n",
    "# And print it\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from last week that JSON objects are just like Python dictionaries, and you can load them using the JSON module. Let's try that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "recipe_data = json.loads(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "Woops! It turns out that data from the internet is in bytes-format. The JSON library really needs it to be a string.\n",
    "For this, we need to use the `decode` method to turn the bytes into unicode. If this sounds like magic to you, don't worry: this is something all programmers have struggled with at some point. \n",
    "\n",
    "For the next class, please watch the video [Pragmatic Unicode, or: How do I stop the pain?](http://nedbatchelder.com/text/unipain.html). And, if you want to learn more about Unicode, read [The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!)](http://www.joelonsoftware.com/articles/Unicode.html).\n",
    "\n",
    "Now, let's just convert the bytes and continue working with the recipe data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decode bytes into utf-8 (unicode).\n",
    "decoded_data = response.content.decode('utf-8')\n",
    "\n",
    "# Load the data.\n",
    "recipe_data = json.loads(decoded_data)\n",
    "\n",
    "# Print the keys.\n",
    "print(recipe_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! A nice way to inspect JSON response dictionaries is to use the built-in pretty printer from the `pprint` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the pretty printer:\n",
    "from pprint import pprint\n",
    "\n",
    "# Print the recipe data:\n",
    "pprint(recipe_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So now we understand the basics of how this API works: ingredients are passed to the website as a comma-separated string, and we get a JSON response back that we can load as a dictionary. The dictionary contains a key called 'results', which maps to a list of results (dictionaries as well). \n",
    "\n",
    "But there is more to this API. Apparently you can't just get one page of results, but you can actually get multiple pages of results. [Here](http://www.recipepuppy.com/api/?i=onions,garlic&q=omelet&p=3) is their example. Some questions:\n",
    "\n",
    "* How can you get more results?\n",
    "* How do you know whether you have *all* results for a given query?\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "Play with the URL and see what happens! Try stuff like p=500000 (or some other high number).\n",
    "We can assume that the website will give a similar page when there are no more results.\n",
    "That's when the algorithm to get all the results needs to stop.\n",
    "\n",
    "### Exercise: dealing with the Recipepuppy API\n",
    "\n",
    "We will work with [this URL for omelettes containing potatoes](http://www.recipepuppy.com/api/?i=potato&q=omelette&p=1), for the simple reason that there aren't that many recipes matching this query. It's nice to have examples like these, because you can easily test your code. Trying out all the numbers shows us that there are **three types of responses**:\n",
    "\n",
    "* http://www.recipepuppy.com/api/?i=potato&q=omelette&p=1 **Returns a JSON file with results.**\n",
    "* http://www.recipepuppy.com/api/?i=potato&q=omelette&p=2 **Gives a 404: page not found error.** (There's a bug in the API!)\n",
    "* http://www.recipepuppy.com/api/?i=potato&q=omelette&p=3 Returns a JSON file with results.\n",
    "* http://www.recipepuppy.com/api/?i=potato&q=omelette&p=4 Returns a JSON file with results.\n",
    "* http://www.recipepuppy.com/api/?i=potato&q=omelette&p=5 Returns a JSON file with results.\n",
    "* http://www.recipepuppy.com/api/?i=potato&q=omelette&p=6 **Returns a JSON file with no results.**\n",
    "\n",
    "We will write some functions to properly deal with this API. Here are all the steps:\n",
    "\n",
    "1. Write a function to return either a dictionary with the results if there is a JSON file, and `None` if the website gives an error.\n",
    "2. Write a generator function to easily loop through the result pages. (We'll explain what a generator function is in a moment.)\n",
    "3. Write a function to collect a specific amount of results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Part 1: write a function to get the results**\n",
    "\n",
    "Using the code below, write a function that returns either a dictionary with the results if there is a JSON file, and None if the website gives an error.\n",
    "\n",
    "HINT: loading the 404 page as a JSON string will raise an error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results(query, ingredients, page):\n",
    "    \"\"\"\n",
    "    Query: string indicating the kind of recipe that you're looking for.\n",
    "    Ingredients: comma-separated string of ingredients.\n",
    "    Page: results page.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE.\n",
    "    try:\n",
    "        # YOUR CODE HERE.\n",
    "        \n",
    "        # The results from recipepuppy.com don't have any page number.\n",
    "        # Let's fix that, because it might be useful in the future.\n",
    "        results['page'] = page\n",
    "        return results\n",
    "    except #SOME KIND OF ERROR IF THE PAGE HAS A 404 MESSAGE:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Part 2: write a generator function to loop over the results**\n",
    "\n",
    "For this part, we first need to understand what a generator function is. Basically, it's a function that produces a sequence of items, one at a time, and forgets each item immediately after producing it, moving to the next one. This is very memory-efficient, because your computer doesn't have to keep a list with all results in memory.\n",
    "\n",
    "OK, that was an abstract definition. Let's see some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simple_counter(n):\n",
    "    \"Generator that produces all the whole numbers up to n.\"\n",
    "    # Initialize a counter named 'count', with value 0.\n",
    "    count = 0\n",
    "    # Keep running until the counter has reached n.\n",
    "    while count != n:\n",
    "        # Produce the current value of the counter.\n",
    "        yield count\n",
    "        # Increase the counter.\n",
    "        count +=1\n",
    "\n",
    "for i in simple_counter(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "At each point in time, `count` only refers to one number. Each iteration of the while-loop, `simple_counter` produces the current value of the counter, but it doesn't remember the value! This is different from a function like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_counter(n):\n",
    "    \"Function that produces a list with all the whole numbers up to n.\"\n",
    "    # Initialize a counter named 'count', with value 0.\n",
    "    count = 0\n",
    "    numbers = []\n",
    "    # Keep running until the counter has reached n.\n",
    "    while count != n:\n",
    "        # Append the current value of the counter to the list.\n",
    "        numbers.append(count)\n",
    "        # Increase the counter.\n",
    "        count +=1\n",
    "    return numbers\n",
    "\n",
    "# Here, the function first produces a list, which Python keeps in memory for the duration of the loop.\n",
    "# Afterwards, the list is removed from memory again. But for a short period of time, it's taking up space.\n",
    "for i in simple_counter(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you call a generator function, it returns a *generator object*. You can use the built-in function `next()` to keep calling the next-to-be-generated value from the generator object until it has produced everything it should. At that point, calling `next()` will result in a `StopIteration` error. Please run the next bit of code to see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generator = simple_counter(2)\n",
    "\n",
    "i = next(generator)\n",
    "print(\"the first value is\", i)\n",
    "\n",
    "i = next(generator)\n",
    "print(\"the second value is\", i)\n",
    "\n",
    "i = next(generator)\n",
    "print(\"the third value is\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what would a generator function for search results look like? Basically it should keep calling the API until there are no more relevant results. This is when the JSON file has an empty list of results. (In this case, we need to raise the StopIteration error because we're defining the stopping criteria ourselves. We'll give you this part of the code for free. Don't worry if this is confusing, we'll discuss everything in class.)\n",
    "\n",
    "Please complete the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def results_generator(query, ingredients):\n",
    "    \"\"\"\n",
    "    Generator to yield all the result pages for the given query and ingredients.\n",
    "    \"\"\"\n",
    "    # Write a loop in which you keep calling the results page until there are no more results.\n",
    "    # Use the 'yield' keyword to produce the results.\n",
    "    # Be sure to also use the sleep() function to pause between calls.\n",
    "    \n",
    "    page_number = 1\n",
    "    # YOUR CODE HERE: write a loop to keep calling the next page.\n",
    "        # YOUR CODE HERE: get the results.\n",
    "        \n",
    "        # If the page gives a 404 error.\n",
    "        if result == None:\n",
    "            continue\n",
    "        \n",
    "        # If there are no more results, raise the StopIteration error so that Python knows to stop.\n",
    "        elif len(result[\"results\"]) == 0:\n",
    "            raise StopIteration\n",
    "        \n",
    "        else:\n",
    "            # YOUR CODE HERE: produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For testing purposes, use this code.\n",
    "results_list = []\n",
    "for result in results_generator(query=\"omelette\",ingredients=\"potato\"):\n",
    "    results_list.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2b: make the generator more robust**\n",
    "\n",
    "A problem with the generator function above is that it might produce an infinite loop if Recipepuppy.com is down. It might be a good idea to add a counter that keeps track of how many times `result` has been equal to `None`, and breaks out of the loop when that number goes over a certain threshold (say, 5 times `None` in a row). How would you do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: write a function to collect a specific amount of results**\n",
    "\n",
    "Suppose you wanted to look for pasta recipes. There are hundreds of them! Getting all recipes from the API would take a long time, and you may only want to have a couple. Hence it's a good idea to write another function to get (at most) a specified number of results. Please complete the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_n_recipes(query,ingredients,n):\n",
    "    \"\"\"\n",
    "    Function that returns at most N results, where N is equal to the number of recipes.\n",
    "    \"\"\"\n",
    "    # NOTE: there are multiple recipes per results page!\n",
    "    return list_of_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More to explore\n",
    "\n",
    "**Hackernews** is a website where people can post URLs to interesting stories, submit polls, show the community something, or ask the community a question. The description of their API is [here](https://github.com/HackerNews/API). \n",
    "\n",
    "**Question**: what kind of things could you do with this data?\n",
    "\n",
    "We will use the Hackernews API in the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many APIs require you to authenticate yourself to the server, before they actually return any results. This is a means to prevent abuse (e.g. overloading the server). This usually means you have to register for the service in order to get an *API key*. We won't cover these in class (we don't want to force you to register for anything), but know there are many public APIs out there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to process your data\n",
    "\n",
    "### Processing the data: HTML\n",
    "\n",
    "Let's take a look at a simple webpage. [Here](http://listserv.linguistlist.org/pipermail/linguist/2016-September/date.html) is one with all postings from the Linguist List in September 2016. Our goal will be to get a list with all the Job postings, including the URL. How do we go about this?\n",
    "\n",
    "Step 1. **Look at the source code first**. We can't do anything without knowing how the page is structured. You can open the page with your browser and inspect the source, or right-click the link and choose \"Save as..\" to save the file and inspect it with a text editor. What would be a good approach?\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "**Possible approaches**\n",
    "\n",
    "1. Use string-methods, look for all the lines with the word 'Jobs' in it, and extract the URL and title from them.\n",
    "2. Use regular expressions, write a pattern to match all links with 'Jobs' in the text.\n",
    "3. Use a module to parse the HTML first, then look for all links with the word 'Jobs'.\n",
    "\n",
    "Let me first emphasize: *There is no wrong way to do this.* If it works, it works. But as the problems you are trying to solve are getting more and more complex, it's increasingly easier to use a high-level approach. (To illustrate: how would you get the full text of [this article](http://www.bbc.com/news/disability-35881779) from the webpage? Parsing HTML is definitely the way to go, here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. **Create a working solution for the problem at hand.** Let's try all three approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python 3 only imports libraries that it hasn't already imported.\n",
    "import requests\n",
    "\n",
    "# Get the data, and convert to string.\n",
    "response = requests.get('http://listserv.linguistlist.org/pipermail/linguist/2016-September/date.html')\n",
    "contents = response.content.decode('utf-8') # We'll use this variable as the starting point for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, try to find all URLs and titles of job-announcements using string-methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Steps:\n",
    "# 1. Split the contents into lines.\n",
    "# 2. Create a list with all the lines containing the word 'Jobs'.\n",
    "# 3. Write a function to extract the URL and title from a line.\n",
    "# 4. Apply that function to each of the lines, and collect the results in another list.\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to find all URLs and titles of job-announcements using regular expressions. Learn about regular expressions [here](https://regexone.com/), and read the documentation for the [re](https://docs.python.org/3/library/re.html) module. Here is a small example of how to use the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Example of how to find all smiley faces in a text.\n",
    "\n",
    "# re.compile is nice because it allows you to define a pattern wherever you want \n",
    "# (put it somewhere prominent & easy to modify) and because your code will be much\n",
    "# faster if you use the pattern often. (Otherwise Python has to compile the pattern \n",
    "# each time you want to use it.)\n",
    "\n",
    "pattern = re.compile(r':-?[\\(\\)]') # The 'r' stands for 'raw string'.\n",
    "results_1 = pattern.findall(\"\"\"Greetings! :) This is a sentence with smileys! :-) \n",
    "                The last one had a nose, probably written by an old person :(\"\"\")\n",
    "\n",
    "# Example of how to use capturing groups.\n",
    "pattern = re.compile('like (\\w+)')\n",
    "results_2 = pattern.findall(\"I like hamsters, but I don't like cleaning the cage.\")\n",
    "\n",
    "print(results_1)\n",
    "print(results_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Steps:\n",
    "# 1. Write a pattern with two capturing groups: one for the URL and one for the text.\n",
    "# 2. Use re.findall(content) to find all the job listings. You will automatically get tuples with the relevant data.\n",
    "#\n",
    "# HINT: you can use the question mark to do non-greedy matching for the asterisk. \n",
    "# '.*?\\n' will match 'everything until the end of the line'. \n",
    "# Contrast this with '.*\\n', which means \"everything up until the last line break\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's use the `lxml` module to find all URLs and titles of job announcements. See the code below for instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "\n",
    "root = html.fromstring(contents)\n",
    "\n",
    "# Modify the XPATH string so that 'links' will contain the right elements.\n",
    "# Use root.getchildren() to explore what the document tree looks like.\n",
    "# You can use getchildren() on other elements as well.\n",
    "links = root.xpath(\"./path/to/link/tag[contains(.,'Jobs')]\")\n",
    "\n",
    "# 'links' will be a list with html elements.\n",
    "# Use dir() to see what you can do with them.\n",
    "# For any link element, you can get the URL like this:\n",
    "# url = link.attrib['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. **How generalizable is your solution?** How many steps does it take to change our solutions to, for example:\n",
    "\n",
    "* Use a different URL (maybe you want to do this in October as well).\n",
    "* Search for a different set of announcements, e.g. *Books*, or *Conferences*.\n",
    "\n",
    "You don't need to implement these changes, though you can if you want to! (Use the code boxes below.) But just read through your solutions to this problem and think about what changes should be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data: NLP tools\n",
    "\n",
    "The common idea for all NLP tools is that they try to structure or transform text in some meaningful way. The question of which tool you should use is only secondary to the question what you want to achieve. To give you a sense of the things you can achieve with standard NLP techniques, we will now look at two tools that you can use to analyze text: **SpaCy** and **pyspotlight**. \n",
    "\n",
    "#### SpaCy: quickly parsing documents\n",
    "\n",
    "SpaCy provides a small NLP pipeline: it takes a raw document, tokenizes it, tags all the tokens, and parses each sentence. On top of that, it also recognizes different types of entities: numbers, locations, and persons. The advantage of SpaCy is that it is really fast, and it has a good accuracy. The downside is that, at the moment, it only works for English and German. There are other tools available for different languages, but those are a bit more difficult to set up. (We can help you with this; ask us after class.)\n",
    "\n",
    "**Installing** \n",
    "\n",
    "To install SpaCy, enter the following commands on the command line.\n",
    "\n",
    "* `conda config --add channels spacy` on the command line\n",
    "* `conda install spacy`. \n",
    "* `python -m spacy.en.download` (if this doesn't work, see [here](http://spacy.io/docs/#getting-started) for updated instructions).\n",
    "\n",
    "**Using SpaCy**\n",
    "\n",
    "First let's load SpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the English parser.\n",
    "# Note for speakers of German: it's also possible to parse German sentences using SpaCy! \n",
    "# See the documentation for more info.\n",
    "from spacy.en import English\n",
    "\n",
    "# The English parser is a class. \n",
    "# If you call it without any arguments, you will get a parser object.\n",
    "# You can use this object to parse documents.\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here's how to parse a document.\n",
    "parsed_document = parser(\"I have an awesome cat. It's sitting on the mat that I bought yesterday.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have an awesome cat.\n",
      "It's sitting on the mat that I bought yesterday.\n"
     ]
    }
   ],
   "source": [
    "# Now you can loop over the document and print each sentence.\n",
    "for sentence in parsed_document.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It\tit\tPRON\tPRP\t6\t23\n",
      "'s\t'\tVERB\tVBZ\t7\t25\n",
      "sitting\tsit\tVERB\tVBG\t8\t28\n",
      "on\ton\tADP\tIN\t9\t36\n",
      "the\tthe\tDET\tDT\t10\t39\n",
      "mat\tmat\tNOUN\tNN\t11\t43\n",
      "that\tthat\tADJ\tWDT\t12\t47\n",
      "I\ti\tPRON\tPRP\t13\t52\n",
      "bought\tbuy\tVERB\tVBD\t14\t54\n",
      "yesterday\tyesterday\tNOUN\tNN\t15\t61\n",
      ".\t.\tPUNCT\t.\t16\t70\n"
     ]
    }
   ],
   "source": [
    "# Print some information about the tokens in the second sentence.\n",
    "sentences = list(parsed_document.sents)\n",
    "for token in sentences[1]:\n",
    "    data = '\\t'.join([token.orth_,\n",
    "                      token.lemma_,\n",
    "                      token.pos_,\n",
    "                      token.tag_,\n",
    "                      str(token.i),   # Turn index into string\n",
    "                      str(token.idx)])# Turn index into string\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question**: what is the difference between `token.pos_` and `token.tag_`? ([read the docs](https://spacy.io/docs/)) to find out.\n",
    "\n",
    "**Question:** what do the different tags mean? Read [this page](http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter \t PERSON\n",
      "British \t NORP\n",
      "J. K. Rowling \t PERSON\n",
      "Harry Potter \t PERSON\n",
      "Hermione Granger \t PERSON\n",
      "Ron Weasley \t PERSON\n",
      "Hogwarts School of Witchcraft and Wizardry \t ORG\n",
      "Harry \t PERSON\n",
      "Lord Voldemort \t PERSON\n",
      "the Ministry of Magic \t ORG\n",
      "Muggles \t PERSON\n"
     ]
    }
   ],
   "source": [
    "# Here's a slightly longer text, from the Wikipedia page about Harry Potter.\n",
    "harry_potter = \"\"\"Harry Potter is a series of fantasy novels written by British author J. K. Rowling. \n",
    "The novels chronicle the life of a young wizard, Harry Potter, and his friends Hermione Granger and Ron Weasley, all of whom are students at Hogwarts School of Witchcraft and Wizardry .\n",
    "The main story arc concerns Harry's struggle against Lord Voldemort, a dark wizard who intends to become immortal, overthrow the wizard governing body known as the Ministry of Magic, and subjugate all wizards and Muggles.\"\"\"\n",
    "\n",
    "sentences = parser(harry_potter)\n",
    "for e in sentences.ents:\n",
    "    first_word = list(e)[0]\n",
    "    etype = first_word.ent_type_\n",
    "    print(e,'\\t',etype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool, but what does NORP mean? According to the [docs](https://spacy.io/docs/#annotation-ner): Nationalities or religious or political groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pyspotlight: 'interpret' sentences using DBpedia\n",
    "\n",
    "Pyspotlight provides an easy way to use DBpedia Spotlight, which is a service you can use to find DBpedia entities in a text. DBpedia is --roughly-- a machine-readable version of Wikipedia. In short, this tool enables us to figure out which entities a text is about.\n",
    "\n",
    "**Installing**\n",
    "\n",
    "To install pyspotlight, enter the following command on the command line.\n",
    "\n",
    "* `pip install pyspotlight`\n",
    "\n",
    "**Using pyspotlight**\n",
    "\n",
    "Pyspotlight has a demo server that we can use for teaching purposes. If you'd like to use Spotlight in the future, it may be wise to set up your own server (you can run it on your laptop) or ask us to set something up for you.\n",
    "\n",
    "* Please run the code below. Is there anything surprising about the output? \n",
    "* If you speak German, Dutch, Hungarian, French, Portuguese, Italian, Russian, Turkish, or Spanish, you could try running Spotlight for any of those languages as well. See the [documentation](https://pypi.python.org/pypi/pyspotlight/0.7.1) for the list of ports in the demo server. Change `2222` below to the relevant port, and you can run Spotlight for your language!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'URI': 'http://dbpedia.org/resource/Harry_Potter_(character)',\n",
       "  'offset': 0,\n",
       "  'percentageOfSecondRank': 2.387108529654866e-09,\n",
       "  'similarityScore': 0.9999999975752871,\n",
       "  'support': 2395,\n",
       "  'surfaceForm': 'Harry Potter',\n",
       "  'types': 'DBpedia:Agent,Schema:Person,Http://xmlns.com/foaf/0.1/Person,DBpedia:Person,DBpedia:FictionalCharacter'},\n",
       " {'URI': 'http://dbpedia.org/resource/Book_series',\n",
       "  'offset': 18,\n",
       "  'percentageOfSecondRank': 0.012025658112639712,\n",
       "  'similarityScore': 0.9880671148841005,\n",
       "  'support': 644,\n",
       "  'surfaceForm': 'series',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Fantasy_literature',\n",
       "  'offset': 28,\n",
       "  'percentageOfSecondRank': 0.05526792303720824,\n",
       "  'similarityScore': 0.9394565473515603,\n",
       "  'support': 825,\n",
       "  'surfaceForm': 'fantasy',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Novel',\n",
       "  'offset': 36,\n",
       "  'percentageOfSecondRank': 3.2418017834321714e-05,\n",
       "  'similarityScore': 0.9999674533482202,\n",
       "  'support': 23076,\n",
       "  'surfaceForm': 'novels',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Peter_Ackroyd',\n",
       "  'offset': 54,\n",
       "  'percentageOfSecondRank': 0.002704726312796819,\n",
       "  'similarityScore': 0.9973025694984762,\n",
       "  'support': 110,\n",
       "  'surfaceForm': 'British author',\n",
       "  'types': 'DBpedia:Agent,Schema:Person,Http://xmlns.com/foaf/0.1/Person,DBpedia:Person,DBpedia:Artist,DBpedia:Writer'},\n",
       " {'URI': 'http://dbpedia.org/resource/J._K._Rowling',\n",
       "  'offset': 75,\n",
       "  'percentageOfSecondRank': 0.0,\n",
       "  'similarityScore': 1.0,\n",
       "  'support': 771,\n",
       "  'surfaceForm': 'Rowling',\n",
       "  'types': 'DBpedia:Agent,Schema:Person,Http://xmlns.com/foaf/0.1/Person,DBpedia:Person,DBpedia:Artist,DBpedia:Writer'},\n",
       " {'URI': 'http://dbpedia.org/resource/Joseph_Stalin',\n",
       "  'offset': 85,\n",
       "  'percentageOfSecondRank': 0.007492935257970516,\n",
       "  'similarityScore': 0.9923080368055438,\n",
       "  'support': 6340,\n",
       "  'surfaceForm': 'The',\n",
       "  'types': 'DBpedia:Agent,Schema:Person,Http://xmlns.com/foaf/0.1/Person,DBpedia:Person,DBpedia:OfficeHolder'},\n",
       " {'URI': 'http://dbpedia.org/resource/Novel',\n",
       "  'offset': 89,\n",
       "  'percentageOfSecondRank': 3.2418017834321714e-05,\n",
       "  'similarityScore': 0.9999674533482202,\n",
       "  'support': 23076,\n",
       "  'surfaceForm': 'novels',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Life',\n",
       "  'offset': 110,\n",
       "  'percentageOfSecondRank': 0.9025995352200947,\n",
       "  'similarityScore': 0.5221610956939501,\n",
       "  'support': 3497,\n",
       "  'surfaceForm': 'life',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Youth',\n",
       "  'offset': 120,\n",
       "  'percentageOfSecondRank': 0.004738747468010577,\n",
       "  'similarityScore': 0.9928256698561141,\n",
       "  'support': 1573,\n",
       "  'surfaceForm': 'young',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Magician_(fantasy)',\n",
       "  'offset': 126,\n",
       "  'percentageOfSecondRank': 1.7380084735122714e-09,\n",
       "  'similarityScore': 0.9999999982613872,\n",
       "  'support': 1577,\n",
       "  'surfaceForm': 'wizard',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Harry_Potter_(character)',\n",
       "  'offset': 134,\n",
       "  'percentageOfSecondRank': 2.387108529654866e-09,\n",
       "  'similarityScore': 0.9999999975752871,\n",
       "  'support': 2395,\n",
       "  'surfaceForm': 'Harry Potter',\n",
       "  'types': 'DBpedia:Agent,Schema:Person,Http://xmlns.com/foaf/0.1/Person,DBpedia:Person,DBpedia:FictionalCharacter'},\n",
       " {'URI': 'http://dbpedia.org/resource/Friendship',\n",
       "  'offset': 156,\n",
       "  'percentageOfSecondRank': 0.36711494605748896,\n",
       "  'similarityScore': 0.7201115322223756,\n",
       "  'support': 709,\n",
       "  'surfaceForm': 'friends',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Hermione_Granger',\n",
       "  'offset': 164,\n",
       "  'percentageOfSecondRank': 0.0,\n",
       "  'similarityScore': 1.0,\n",
       "  'support': 337,\n",
       "  'surfaceForm': 'Hermione Granger',\n",
       "  'types': 'DBpedia:Agent,Schema:Person,Http://xmlns.com/foaf/0.1/Person,DBpedia:Person,DBpedia:FictionalCharacter'},\n",
       " {'URI': 'http://dbpedia.org/resource/Ron_Weasley',\n",
       "  'offset': 185,\n",
       "  'percentageOfSecondRank': 0.0,\n",
       "  'similarityScore': 1.0,\n",
       "  'support': 375,\n",
       "  'surfaceForm': 'Ron Weasley',\n",
       "  'types': 'DBpedia:Agent,Schema:Person,Http://xmlns.com/foaf/0.1/Person,DBpedia:Person,DBpedia:FictionalCharacter'},\n",
       " {'URI': 'http://dbpedia.org/resource/Student',\n",
       "  'offset': 214,\n",
       "  'percentageOfSecondRank': 2.8625785575822086e-05,\n",
       "  'similarityScore': 0.9999648176681732,\n",
       "  'support': 6208,\n",
       "  'surfaceForm': 'students',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Hogwarts',\n",
       "  'offset': 226,\n",
       "  'percentageOfSecondRank': 0.0,\n",
       "  'similarityScore': 1.0,\n",
       "  'support': 1836,\n",
       "  'surfaceForm': 'Hogwarts',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/School',\n",
       "  'offset': 235,\n",
       "  'percentageOfSecondRank': 0.0009798957792206012,\n",
       "  'similarityScore': 0.999004446364561,\n",
       "  'support': 13586,\n",
       "  'surfaceForm': 'School',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Witchcraft',\n",
       "  'offset': 245,\n",
       "  'percentageOfSecondRank': 2.2718446766853874e-05,\n",
       "  'similarityScore': 0.9999772820693676,\n",
       "  'support': 4949,\n",
       "  'surfaceForm': 'Witchcraft',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Magician_(fantasy)',\n",
       "  'offset': 260,\n",
       "  'percentageOfSecondRank': 8.25973393810128e-12,\n",
       "  'similarityScore': 0.9999999999917577,\n",
       "  'support': 1577,\n",
       "  'surfaceForm': 'Wizardry',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Saint_Laurent_Boulevard',\n",
       "  'offset': 271,\n",
       "  'percentageOfSecondRank': 0.0,\n",
       "  'similarityScore': 0.9999999999997726,\n",
       "  'support': 117,\n",
       "  'surfaceForm': 'The main',\n",
       "  'types': 'Schema:Place,DBpedia:Place,DBpedia:ArchitecturalStructure,DBpedia:Infrastructure,DBpedia:RouteOfTransportation,DBpedia:Road'},\n",
       " {'URI': 'http://dbpedia.org/resource/Story_arc',\n",
       "  'offset': 280,\n",
       "  'percentageOfSecondRank': 3.7412687109006035e-08,\n",
       "  'similarityScore': 0.999999944378432,\n",
       "  'support': 1079,\n",
       "  'surfaceForm': 'story arc',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Harry_Potter_(character)',\n",
       "  'offset': 299,\n",
       "  'percentageOfSecondRank': 1.837383364931878e-10,\n",
       "  'similarityScore': 0.9999999998162821,\n",
       "  'support': 2395,\n",
       "  'surfaceForm': 'Harry',\n",
       "  'types': 'DBpedia:Agent,Schema:Person,Http://xmlns.com/foaf/0.1/Person,DBpedia:Person,DBpedia:FictionalCharacter'},\n",
       " {'URI': 'http://dbpedia.org/resource/Lord_Voldemort',\n",
       "  'offset': 324,\n",
       "  'percentageOfSecondRank': 0.0,\n",
       "  'similarityScore': 1.0,\n",
       "  'support': 633,\n",
       "  'surfaceForm': 'Lord Voldemort',\n",
       "  'types': 'DBpedia:Agent,Schema:Person,Http://xmlns.com/foaf/0.1/Person,DBpedia:Person,DBpedia:FictionalCharacter'},\n",
       " {'URI': 'http://dbpedia.org/resource/Magic_in_Harry_Potter',\n",
       "  'offset': 342,\n",
       "  'percentageOfSecondRank': 0.0,\n",
       "  'similarityScore': 1.0,\n",
       "  'support': 636,\n",
       "  'surfaceForm': 'dark wizard',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Immortality',\n",
       "  'offset': 376,\n",
       "  'percentageOfSecondRank': 1.408978010917982e-05,\n",
       "  'similarityScore': 0.9999759726902748,\n",
       "  'support': 1137,\n",
       "  'surfaceForm': 'immortal',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Magician_(fantasy)',\n",
       "  'offset': 400,\n",
       "  'percentageOfSecondRank': 1.7380084735122714e-09,\n",
       "  'similarityScore': 0.9999999982613872,\n",
       "  'support': 1577,\n",
       "  'surfaceForm': 'wizard',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Government',\n",
       "  'offset': 407,\n",
       "  'percentageOfSecondRank': 0.9458386164091137,\n",
       "  'similarityScore': 0.49670283765216056,\n",
       "  'support': 11075,\n",
       "  'surfaceForm': 'governing body',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Ministry_of_Magic',\n",
       "  'offset': 435,\n",
       "  'percentageOfSecondRank': 2.1318510702893044e-25,\n",
       "  'similarityScore': 1.0,\n",
       "  'support': 541,\n",
       "  'surfaceForm': 'Ministry',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Magic_(paranormal)',\n",
       "  'offset': 447,\n",
       "  'percentageOfSecondRank': 0.00038027189886991226,\n",
       "  'similarityScore': 0.9996197145839661,\n",
       "  'support': 3612,\n",
       "  'surfaceForm': 'Magic',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Harry_Potter_universe',\n",
       "  'offset': 472,\n",
       "  'percentageOfSecondRank': 1.3813269146493607e-10,\n",
       "  'similarityScore': 0.9999999998618705,\n",
       "  'support': 360,\n",
       "  'surfaceForm': 'wizards',\n",
       "  'types': ''},\n",
       " {'URI': 'http://dbpedia.org/resource/Muggle',\n",
       "  'offset': 484,\n",
       "  'percentageOfSecondRank': 4.482329596198474e-38,\n",
       "  'similarityScore': 1.0,\n",
       "  'support': 187,\n",
       "  'surfaceForm': 'Muggles',\n",
       "  'types': ''}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spotlight\n",
    "\n",
    "demo_server = 'http://spotlight.sztaki.hu:2222/rest/annotate'\n",
    "\n",
    "# Annotate the Harry Potter text we've seen earlier.\n",
    "spotlight.annotate(demo_server, harry_potter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other tools (not covered in class)\n",
    "\n",
    "Unfortunately we cannot cover all NLP tools in this course. Below is a short list of tools that might be useful to you in the future. You can either use these tools as standalone programs (and then process their output using Python), or you can choose to use a *wrapper* that allows you to call these tools from inside Python.\n",
    "\n",
    "* Treetagger is a tool for tokenization and part-of-speech tagging in many languages. [Here](http://treetaggerwrapper.readthedocs.io/en/latest/) is a Python interface for it. \n",
    "* Stanford CoreNLP is a suite of NLP tools (constituting a full pipeline). [Here](https://github.com/dasmith/stanford-corenlp-python) is a library to interact with those tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Here are some exercises to help you practice your data processing skills! (These are not mandatory, but we do recommend you to try these.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Harry Potter\n",
    "\n",
    "Use the requests library to get [the Harry Potter article from Wikipedia in JSON format]([this URL](https://en.wikipedia.org/w/api.php?action=query&prop=revisions&rvprop=content&format=json&&titles=Harry%20Potter). Then, answer the following questions:\n",
    "\n",
    "1. Who are the frequent characters mentioned in the Wikipedia article? (HINT: you might want to use SpaCy)\n",
    "2. What are the most frequent locations in the Wikipedia article?\n",
    "3. What are the most cited books on this page? What about websites? (HINT: this is a job for regular expressions!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Hackernews\n",
    "\n",
    "The [Hackernews API](https://github.com/HackerNews/API) is a nice source of discussions between people, and of opiniated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
