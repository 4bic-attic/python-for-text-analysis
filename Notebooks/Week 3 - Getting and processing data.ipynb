{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting and processing data\n",
    "\n",
    "This week, we will cover the topic of getting and processing data. Given a research problem, where can you find the relevant data? How do you obtain the data? And how do you actually process the data? This notebook aims to guide you through the process.\n",
    "\n",
    "**Important**: this notebook requires you to download and install several items. Please install them before class.\n",
    "\n",
    "## Where to find data\n",
    "\n",
    "**Curated**\n",
    "\n",
    "* Corpora (Brown ([NLTK version](http://www.nltk.org/book/ch02.html)), [OANC](http://www.anc.org/data/oanc/download/), [UMBC WebBase](http://ebiquity.umbc.edu/resource/html/id/351))\n",
    "* Psycholinguistic data (sometimes known as 'norms' in the Psychology literature)\n",
    "* DBpedia\n",
    "* Open data (e.g. [Dutch](https://data.overheid.nl/), [American](https://www.data.gov/))\n",
    "\n",
    "**The web**\n",
    "\n",
    "* [USENET](http://www.psych.ualberta.ca/~westburylab/downloads/usenetcorpus.download.html)\n",
    "* [Internet Archive](https://archive.org/)\n",
    "* [Project Gutenberg](https://www.gutenberg.org/)\n",
    "* Wikipedia ([dumps](https://dumps.wikimedia.org/), [export]())\n",
    "* [Web data commons](http://webdatacommons.org/)\n",
    "\n",
    "**Do it yourself**\n",
    "\n",
    "* [BootCat](http://bootcat.sslmit.unibo.it/)\n",
    "* Experiments\n",
    "* Annotating\n",
    "* Crowdsourcing\n",
    "* ...\n",
    "\n",
    "## How to get the data\n",
    "\n",
    "### Downloading directly\n",
    "\n",
    "Here are three ways to download data from the web, each with their own use cases.\n",
    "\n",
    "* Browser (loads of data available online)\n",
    "* Command line: `wget` ([manual](https://www.gnu.org/software/wget/manual/wget.html))\n",
    "* Python: `requests`, `urllib`\n",
    "\n",
    "If you see some dataset online, or you just want to download a webpage, there is no better way than to use your browser and either save the page (from the File menu), or to right-click and press \"save as..\". But for more complex cases, you'll want to automate the process. \n",
    "\n",
    "The command line `wget` tool is like a swiss pocket knife for downloading stuff in bulk. For example, if you have a list of URLs in a text file called `list_of_urls.txt`, you can just use `wget -i list_of_urls.txt` to download all the files. You can also use the `wget` module in Python. For more complicated procedures, it's easier to just use the `requests` or `urllib` library.\n",
    "\n",
    "Here is how we downloaded the Linguist List data for this course:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import urllib.request\n",
    "import time\n",
    "\n",
    "base_url = 'http://listserv.linguistlist.org/pipermail/linglite/'\n",
    "years = [str(year) for year in range(1997,2016)]\n",
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
    "          'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "for year in years:\n",
    "    # OS-independent way of creating the path to the folder.\n",
    "    path = os.path.join('..', 'linguistlist', year)\n",
    "    # Make the necessary folder.\n",
    "    os.makedirs(path)\n",
    "    \n",
    "    for month in months:\n",
    "        # Update variables.\n",
    "        filename = '{}-{}.txt.gz'.format(year, month)\n",
    "        path_with_file = os.path.join(path, filename)\n",
    "        url = base_url + filename\n",
    "        \n",
    "        # Write the data to disk.\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            # Use the 'wb' flag because the response contents are bytes.\n",
    "            with open(path_with_file, 'wb') as outfile:\n",
    "                data = response.read()\n",
    "                outfile.write(data)\n",
    "        \n",
    "        # Be nice to the server.\n",
    "        time.sleep(2)\n",
    "```\n",
    "\n",
    "How did we do this?\n",
    "\n",
    "* First, we went to the [Linguist List archive website](http://listserv.linguistlist.org/pipermail/linglite/). The archive looks nice, but it's a lot of work to download all of those files by hand!\n",
    "* Then, we inspected the **source** of the webpage. In Firefox, you can do this by going to `Tools/Developer/Page Source`. In Chrome: `View/Developer/View Source`. Most other browsers offer this functionality as well.\n",
    "* We saw that the URLs for the monthly archives are very regular. This is good, it means that we can exploit this regularity.\n",
    "* Then, we decided on a local structure: we want to have one folder for every year, in which all the archives for that year are stored. This structure determined the structure of our program.\n",
    "* If you don't download files often, search online for a good way to do this. Many programmers would be lost without Google/StackOverflow! The first thing we found was the `urllib` library. But a solution using the `requests` library would also be OK! That would look like this:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "# Get the data:\n",
    "r = requests.get('http://listserv.linguistlist.org/pipermail/linglite/2016-September.txt.gz')\n",
    "\n",
    "# Use the 'wb' flag because the response contents are bytes.\n",
    "with open('September.txt.gz','wb') as f:\n",
    "\t# Write the data:\n",
    "\tf.write(r.content)\n",
    "```\n",
    "\n",
    "* It turns out that you can use a context manager (`with`-statement) to treat online sources as files. Cool! That means we can use two context managers (1) to get the file from the internet, and (2) to write the file to disk.\n",
    "* It's good practice to make your computer wait a little between requests. So we used the `sleep` function from the `time` module to wait 2 seconds after each download.\n",
    "\n",
    "\n",
    "#### Class discussion\n",
    "This was a simple example that doesn't require us to do any parsing of the webpage itself. But how would you write a function that takes a URL like [this one](http://listserv.linguistlist.org/pipermail/linguist/2016-September/date.html) and returns all job descriptions? What would be your approach (on a high level)? \n",
    "\n",
    "We will revisit this problem in the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an API\n",
    "\n",
    "An API (*application programming interface*) provides a way for programs to interact with applications running independently. Those applications could either be running on your own computer, or they could be running somewhere else. We will be working with online APIs, specifically APIs providing the interface to some database. \n",
    "\n",
    "General guidelines for using APIs:\n",
    "\n",
    "1. Try to minimize the number of requests you make. Can you be selective before putting in your requests? \n",
    "2. Try to spread your requests so that you don't overload the server.\n",
    "3. Try to cache your results so that you don't request the same thing twice. (Think about multiple sessions and testing your code.)\n",
    "\n",
    "In short: developers providing APIs are doing us a favor. Acting nice to them is the least we can do.\n",
    "\n",
    "#### Bare APIs and wrappers\n",
    "\n",
    "APIs work like this: you send them a request (possibly with some additional information), and they send you the relevant data back. Sometimes you have to send these requests explicitly in your code, but other times there will be a *wrapper* where people have written code to provide a nice interface for you to use.\n",
    "\n",
    "**Geopy** is a nice example of a wrapper around several geolocation APIs. Read the documentation [here](https://geopy.readthedocs.io/en/1.10.0/). You can install Geopy using `pip install geopy`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is no wrapper, you just treat the API as if you are downloading something from the URL. Let's go through some examples. Both of these provide output in JSON format.\n",
    "\n",
    "**Recipepuppy** is a website where you can search for recipes you can make with a particular set of ingredients. The description of their API is [here](http://www.recipepuppy.com/about/api/). So how do we make this work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the ingredients as a comma-separated list.bacon,eggs\n",
      "b'{\"title\":\"Recipe Puppy\",\"version\":0.1,\"href\":\"http:\\\\/\\\\/www.recipepuppy.com\\\\/\",\"results\":[{\"title\":\"Grandpa Farrell\\'s  Scrambled Eggs\",\"href\":\"http:\\\\/\\\\/www.recipezaar.com\\\\/Grandpa-Farrells-Scrambled-Eggs-123977\",\"ingredients\":\"bacon, eggs\",\"thumbnail\":\"http:\\\\/\\\\/img.recipepuppy.com\\\\/686617.jpg\"},{\"title\":\"\\\\nMicrowave Scrambled Eggs Recipe\\\\n\\\\n\",\"href\":\"http:\\\\/\\\\/cookeatshare.com\\\\/recipes\\\\/microwave-scrambled-eggs-30382\",\"ingredients\":\"eggs, bacon\",\"thumbnail\":\"http:\\\\/\\\\/img.recipepuppy.com\\\\/810118.jpg\"},{\"title\":\"Quicker-than-Fast Food Egg Sandwich \\\\r\\\\n\\\\r\\\\n\",\"href\":\"http:\\\\/\\\\/www.kraftfoods.com\\\\/kf\\\\/recipes\\\\/quicker-than-fast-food-egg-sandwich-69201.aspx\",\"ingredients\":\"english muffin, eggs, bacon\",\"thumbnail\":\"http:\\\\/\\\\/img.recipepuppy.com\\\\/601028.jpg\"},{\"title\":\"Quicker-than-Fast Food Egg Sandwich \\\\r\\\\n\\\\r\\\\n\",\"href\":\"http:\\\\/\\\\/www.kraftfoods.com\\\\/kf\\\\/recipes\\\\/quicker-than-fast-food-egg-sandwich-69201.aspx?cm_re=1-_-1-_-RecipeAlsoEnjoy\",\"ingredients\":\"english muffin, eggs, bacon\",\"thumbnail\":\"http:\\\\/\\\\/img.recipepuppy.com\\\\/675413.jpg\"},{\"title\":\"Heart Attack Eggs\",\"href\":\"http:\\\\/\\\\/allrecipes.com\\\\/Recipe\\\\/Heart-Attack-Eggs\\\\/Detail.aspx\",\"ingredients\":\"bacon, eggs, salt\",\"thumbnail\":\"http:\\\\/\\\\/img.recipepuppy.com\\\\/7523.jpg\"},{\"title\":\"Breakfast Burritos\",\"href\":\"http:\\\\/\\\\/allrecipes.com\\\\/Recipe\\\\/Breakfast-Burritos\\\\/Detail.aspx\",\"ingredients\":\"bacon, cheddar cheese, eggs\",\"thumbnail\":\"http:\\\\/\\\\/img.recipepuppy.com\\\\/14372.jpg\"},{\"title\":\"Dad\\'s Souper Brunch\",\"href\":\"http:\\\\/\\\\/allrecipes.com\\\\/Recipe\\\\/Dads-Souper-Brunch\\\\/Detail.aspx\",\"ingredients\":\"bacon, eggs, english muffin\",\"thumbnail\":\"http:\\\\/\\\\/img.recipepuppy.com\\\\/7522.jpg\"},{\"title\":\"Breakfast in a Hurry\",\"href\":\"http:\\\\/\\\\/www.recipezaar.com\\\\/Breakfast-in-a-Hurry-155256\",\"ingredients\":\"cheddar cheese, bacon, eggs\",\"thumbnail\":\"http:\\\\/\\\\/img.recipepuppy.com\\\\/190160.jpg\"},{\"title\":\"Bacon Weave Recipe\",\"href\":\"http:\\\\/\\\\/www.grouprecipes.com\\\\/83205\\\\/bacon-weave.html\",\"ingredients\":\"bacon, cheese, eggs\",\"thumbnail\":\"http:\\\\/\\\\/img.recipepuppy.com\\\\/368900.jpg\"},{\"title\":\"\\\\nSalade D\\' Spinach Recipe\\\\n\\\\n\",\"href\":\"http:\\\\/\\\\/cookeatshare.com\\\\/recipes\\\\/salade-d-spinach-50407\",\"ingredients\":\"spinach, eggs, bacon\",\"thumbnail\":\"http:\\\\/\\\\/img.recipepuppy.com\\\\/820015.jpg\"}]}'\n"
     ]
    }
   ],
   "source": [
    "# This library comes pre-installed with Anaconda. We use it to send requests to the web.\n",
    "import requests\n",
    "\n",
    "# Get the ingredients\n",
    "ingredients = input('Please enter the ingredients as a comma-separated list.\\n')\n",
    "\n",
    "# Remove spaces if there are any. (This makes the script more robust.)\n",
    "ingredients.replace(' ','')\n",
    "\n",
    "# Prepare the API request URL\n",
    "base_url = \"http://www.recipepuppy.com/api/?i=\"\n",
    "api_request = base_url + ingredients\n",
    "\n",
    "# Get the response\n",
    "response = requests.get(api_request)\n",
    "\n",
    "# And print it\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from last week that JSON objects are just like Python dictionaries, and you can load them using the JSON module. Let's try that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, not 'bytes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-28da6560cd3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrecipe_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         raise TypeError('the JSON object must be str, not {!r}'.format(\n\u001b[0;32m--> 312\u001b[0;31m                             s.__class__.__name__))\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'\\ufeff'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         raise JSONDecodeError(\"Unexpected UTF-8 BOM (decode using utf-8-sig)\",\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, not 'bytes'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "recipe_data = json.loads(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "Woops! It turns out that data from the internet is in bytes-format. The JSON library really needs it to be a string.\n",
    "For this, we need to use the `decode` method to turn the bytes into unicode. If this sounds like magic to you, don't worry: this is something all programmers have struggled with at some point. \n",
    "\n",
    "For the next class, please watch the video [Pragmatic Unicode, or: How do I stop the pain?](http://nedbatchelder.com/text/unipain.html). And, if you want to learn more about Unicode, read [The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!)](http://www.joelonsoftware.com/articles/Unicode.html).\n",
    "\n",
    "Now, let's just convert the bytes and continue working with the recipe data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'version', 'href', 'results'])\n"
     ]
    }
   ],
   "source": [
    "# Decode bytes into utf-8 (unicode).\n",
    "decoded_data = response.content.decode('utf-8')\n",
    "\n",
    "# Load the data.\n",
    "recipe_data = json.loads(decoded_data)\n",
    "\n",
    "# Print the keys.\n",
    "print(recipe_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! A nice way to inspect JSON response dictionaries is to use the built-in pretty printer from the `pprint` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'href': 'http://www.recipepuppy.com/',\n",
      " 'results': [{'href': 'http://www.recipezaar.com/Grandpa-Farrells-Scrambled-Eggs-123977',\n",
      "              'ingredients': 'bacon, eggs',\n",
      "              'thumbnail': 'http://img.recipepuppy.com/686617.jpg',\n",
      "              'title': \"Grandpa Farrell's  Scrambled Eggs\"},\n",
      "             {'href': 'http://cookeatshare.com/recipes/microwave-scrambled-eggs-30382',\n",
      "              'ingredients': 'eggs, bacon',\n",
      "              'thumbnail': 'http://img.recipepuppy.com/810118.jpg',\n",
      "              'title': '\\nMicrowave Scrambled Eggs Recipe\\n\\n'},\n",
      "             {'href': 'http://www.kraftfoods.com/kf/recipes/quicker-than-fast-food-egg-sandwich-69201.aspx',\n",
      "              'ingredients': 'english muffin, eggs, bacon',\n",
      "              'thumbnail': 'http://img.recipepuppy.com/601028.jpg',\n",
      "              'title': 'Quicker-than-Fast Food Egg Sandwich \\r\\n\\r\\n'},\n",
      "             {'href': 'http://www.kraftfoods.com/kf/recipes/quicker-than-fast-food-egg-sandwich-69201.aspx?cm_re=1-_-1-_-RecipeAlsoEnjoy',\n",
      "              'ingredients': 'english muffin, eggs, bacon',\n",
      "              'thumbnail': 'http://img.recipepuppy.com/675413.jpg',\n",
      "              'title': 'Quicker-than-Fast Food Egg Sandwich \\r\\n\\r\\n'},\n",
      "             {'href': 'http://allrecipes.com/Recipe/Heart-Attack-Eggs/Detail.aspx',\n",
      "              'ingredients': 'bacon, eggs, salt',\n",
      "              'thumbnail': 'http://img.recipepuppy.com/7523.jpg',\n",
      "              'title': 'Heart Attack Eggs'},\n",
      "             {'href': 'http://allrecipes.com/Recipe/Breakfast-Burritos/Detail.aspx',\n",
      "              'ingredients': 'bacon, cheddar cheese, eggs',\n",
      "              'thumbnail': 'http://img.recipepuppy.com/14372.jpg',\n",
      "              'title': 'Breakfast Burritos'},\n",
      "             {'href': 'http://allrecipes.com/Recipe/Dads-Souper-Brunch/Detail.aspx',\n",
      "              'ingredients': 'bacon, eggs, english muffin',\n",
      "              'thumbnail': 'http://img.recipepuppy.com/7522.jpg',\n",
      "              'title': \"Dad's Souper Brunch\"},\n",
      "             {'href': 'http://www.recipezaar.com/Breakfast-in-a-Hurry-155256',\n",
      "              'ingredients': 'cheddar cheese, bacon, eggs',\n",
      "              'thumbnail': 'http://img.recipepuppy.com/190160.jpg',\n",
      "              'title': 'Breakfast in a Hurry'},\n",
      "             {'href': 'http://www.grouprecipes.com/83205/bacon-weave.html',\n",
      "              'ingredients': 'bacon, cheese, eggs',\n",
      "              'thumbnail': 'http://img.recipepuppy.com/368900.jpg',\n",
      "              'title': 'Bacon Weave Recipe'},\n",
      "             {'href': 'http://cookeatshare.com/recipes/salade-d-spinach-50407',\n",
      "              'ingredients': 'spinach, eggs, bacon',\n",
      "              'thumbnail': 'http://img.recipepuppy.com/820015.jpg',\n",
      "              'title': \"\\nSalade D' Spinach Recipe\\n\\n\"}],\n",
      " 'title': 'Recipe Puppy',\n",
      " 'version': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Import the pretty printer:\n",
    "from pprint import pprint\n",
    "\n",
    "# Print the recipe data:\n",
    "pprint(recipe_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hackernews** is a website where people can post URLs to interesting stories, submit polls, show the community something, or ask the community a question. The description of their API is [here](https://github.com/HackerNews/API). **Question**: what kind of things could you do with this data?\n",
    "\n",
    "We will use the Hackernews API in the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many APIs require you to authenticate yourself to the server, before they actually return any results. This is a means to prevent abuse (e.g. overloading the server). This usually means you have to register for the service in order to get an *API key*. We won't cover these in class (we don't want to force you to register for anything), but know there are many public APIs out there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to process your data\n",
    "\n",
    "### Processing the data: HTML\n",
    "\n",
    "\n",
    "### Processing data: NLP tools\n",
    "\n",
    "The common idea for all NLP tools is that they try to structure or transform text in some meaningful way. The question of which tool you should use is only secondary to the question what you want to achieve. To give you a sense of the things you can achieve with standard NLP techniques, we will now look at two tools that you can use to analyze text: **SpaCy** and **pyspotlight**. \n",
    "\n",
    "#### SpaCy: quickly parsing documents\n",
    "\n",
    "SpaCy provides a small NLP pipeline: it takes a raw document, tokenizes it, tags all the tokens, and parses each sentence. On top of that, it also recognizes different types of entities: numbers, locations, and persons. The advantage of SpaCy is that it is really fast, and it has a good accuracy. The downside is that, at the moment, it only works for English and German. There are other tools available for different languages, but those are a bit more difficult to set up. (We can help you with this; ask us after class.)\n",
    "\n",
    "**Installing** \n",
    "\n",
    "To install SpaCy, enter the following commands on the command line.\n",
    "\n",
    "* `conda config --add channels spacy` on the command line\n",
    "* `conda install spacy`. \n",
    "* `python -m spacy.en.download` (if this doesn't work, see [here](http://spacy.io/docs/#getting-started) for updated instructions).\n",
    "\n",
    "**Using SpaCy**\n",
    "\n",
    "EXAMPLES AND EXERCISES.\n",
    "\n",
    "#### pyspotlight: 'interpret' sentences using DBpedia\n",
    "\n",
    "Pyspotlight provides an easy way to use DBpedia Spotlight, which is a service you can use to find DBpedia entities in a text. DBpedia is --roughly-- a machine-readable version of Wikipedia. In short, this tool enables us to figure out which entities a text is about.\n",
    "\n",
    "**Installing**\n",
    "\n",
    "To install pyspotlight, enter the following command on the command line.\n",
    "\n",
    "* `pip install pyspotlight`\n",
    "\n",
    "**Using pyspotlight**\n",
    "\n",
    "EXAMPLES AND EXERCISES.\n",
    "\n",
    "#### Other tools (not covered in class)\n",
    "\n",
    "Unfortunately we cannot cover all NLP tools in this course. Below is a short list of tools that might be useful to you in the future. You can either use these tools as standalone programs (and then process their output using Python), or you can choose to use a *wrapper* that allows you to call these tools from inside Python.\n",
    "\n",
    "* Treetagger is a tool for tokenization and part-of-speech tagging in many languages. [Here](https://github.com/miotto/treetagger-python) is a Python interface for it. \n",
    "* Stanford CoreNLP is a suite of NLP tools (constituting a full pipeline). [Here](https://github.com/dasmith/stanford-corenlp-python) is a library to interact with those tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
